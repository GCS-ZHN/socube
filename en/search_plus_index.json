{"./":{"url":"./","title":"Introduction","keywords":"","body":"Introduction SoCube workflow 1.1 Basic Information SoCube V1.0 is terminal command-based software written in Python without a graphical user interface (GUI), and can run on any server, personal computer, which can run the Python program. 1.2 Writing Purpose This gitbook is a user's guide for SoCube V1.0. It will introduce the requirement, installment and usage of SoCube V1.0. Besides, it provides some common problems' solutions when using SoCube. 1.3 Background High-throughput single-cell RNA sequencing (scRNA-seq) is widely used in biomedical research [1-6]. However, due to the limitations of sequencing technology, some doublets (or multiplets) formed by the combination of two (or more) cells will be generated during the sequencing process. Doublets are equivalent to the cell types not present in the sample and can severely interfere with the true statistical distribution of cells and genes, thus affecting distribution-dependent downstream studies [7]. Therefore, the Laboratory of Innovative Drug Research and Bioinformatics at Zhejiang University (hereinafter referred to as \"we\") developed SoCube to detect doublets generated in single-cell high-throughput sequencing. console.log(\"plugin-popup....\");document.onclick = function(e){ e.target.tagName === \"IMG\" && window.open(e.target.src,e.target.src)}img{cursor:pointer}"},"2-requirement.html":{"url":"2-requirement.html","title":"Requirement","keywords":"","body":"Requirement 2.1 Hardware SoCube's hardware development environment is based on the XII Gen Intel I7-12700F CPU and the NVIDIA GeForce RTX 3060 GPU. SoCube is theoretically capable of running on any device that can run Python and PyTorch. The recommended hardware runtime environment is as follows: RAM capacity of not less than 8GB CPU core number not less than 6 cores NVIDIA discrete graphics card with CUDA acceleration and no less than 4GB of video memory 2.2 Software SoCube is written in Python v3.8, and Visual Studio Code v1.68.1 is used as the code writing tool. The development OS is Windows 11. SoCube supports use in any software environment that can run Python and PyTorch. The recommended software runtime environment is as follows: OS: Windows 10/11, Linux CentOS 7/8, Mac OS Python: v3.7 and above PyTorch: v1.8.1 and higher GPU versions console.log(\"plugin-popup....\");document.onclick = function(e){ e.target.tagName === \"IMG\" && window.open(e.target.src,e.target.src)}img{cursor:pointer}"},"3-install.html":{"url":"3-install.html","title":"Installation","keywords":"","body":"Installation 3.1 CUDA Installation SoCube is developed based on deep convolutional neural networks, and we strongly recommend users to use GPU accelerated computation in an environment with NVIDIA GPU and NVIDIA CUDA compute suite. For having a CUDA-supported NVIDIA GPU, users first need to install CUDA, which can be downloaded and installed from NVIDIA. NVIDIA cuda download page After the installation is completed, users can enter \"nvidia-smi\" in the terminal to view their graphics card information and CUDA version information, as shown below, the graphics card is GeForce RTX 3060, the driver version is 516.59, CUDA version is 11.7. nvidia-smi output of nvidia-smi 3.2 SoCube Installation PipDockerpip install socube # pip installation socube -v # check the installed version SoCube has been packaged and published to the Python official repository PyPi. Users can open a terminal (such as Windows PowerShell, Bash, etc.) and use the pip command to install it. For users in China, it is recommended to use the Tsinghua University mirror to accelerate the download during installation. The following uses the Windows operating system as an example.1. Python InstallationSoCube is a software developed based on Python, and it needs Python interpreter to run the software. Users could download Python from Python official website.Python official websiteAs shown below, follow the installation package prompts to install Python and check the box to add Python to the PATH environment variable (this environment variable defines the search path for terminal commands; if you do not add it, you cannot use Python directly in the terminal).Python installation page2. Access to terminal command environmentPip is a package manager provided by Python to download all kinds of packages developed by Python, but it needs to be used in a terminal. Two kinds of terminals are provided under Windows, Windows PowerShell and Cmd, we recommend using PowerShell. use \"Win+R \" shortcut and run powershell to quickly enter PowerShell terminal.Run powershell3. Execute the pip command to installExecute the aforementioned command in the terminal to install SoCube V1.0, which is recommended for users in China to use the Tsinghua University mirror to accelerate software download. When you see \"Successfully installed *** socube-1.0\" , it means the download and installation are successful. After successful installation, continue to enter socube -v in the current terminal to see the software version. The -i parameter is recommended for users in China (https://pypi.tuna.tsinghua.edu.cn/simple/).pip install socube==1.0 -f https://pypi.tuna.tsinghua.edu.cn/simple/ 4. Notes on PyTorchAlthough PyTorch is automatically installed when executing pip install socube, versions provided by some mirror sites may be CPU-only version, so users are advised to check if the installed version supports GPU (torch.cuda.is_available() will be True when GPU and CUDA are properly configured). It is recommended to download torch from the PyTorch official website.pip install torch==1.8.1+cu111 torchvision==0.9.1+cu111 -f https://download.pytorch.org/whl/torch_stable.html sudo docker pull gcszhn/socube:latest Docker is a containerized technology that isolates software in a sandbox, named as container. Containers are isolated from the physical device (named as container's host) and from the containers to each other. A container has the complete software environment in which the application runs and does not depend on the host software environment at all. Containers can be published as images and shared between devices with docker installed without additional installation. SoCube's docker image have been built and published on Docker Hub. Users who already have docker installed can obtain SoCube by executing the above command in the terminal. In addition, users can package a custom docker image of their own, with open-source Dockerflie.git clone https://github.com/GCS-ZHN/socube.git cd socube sudo docker build docker -t gcszhn/socube console.log(\"plugin-popup....\");document.onclick = function(e){ e.target.tagName === \"IMG\" && window.open(e.target.src,e.target.src)}img{cursor:pointer}"},"4-usage.html":{"url":"4-usage.html","title":"Usage","keywords":"","body":"Usage 4.1 Basic usage 1. Format of input data SoCube's data input is a scRNA-seq UMI count matrix with rows of cells, columns of genes, and values of UMI counts. SoCube accepts two data formats: (1)DataFrame objects in HDF5 format saved by Python pandas library; (2)AnnData objects in H5AD format (a customized HDF5 format) saved by Python anndata library. People working in the field of single-cell omics have some basic knowledge of data processing, so this manual does not specifically describe how to convert from other formats to the above formats. 2. Running SoCube SoCube runs under the terminal like the aforementioned pip. The advantage is that it can run on many servers without GUI. Assuming that the input file is \"D:\\data\\pbmc-1C-dm.h5ad\", you can enter the following command in the terminal to run the software, and then you will see the software start and output logs in the terminal. The parameter -i (or --input) indicates the specified input file. socube --input \"D:\\data\\pbmc-1C-dm.h5ad\" Start-up socube When the process is finished, the doublet detection results and the intermediate files will be put together with the input files by default, folders named as embedding, plots, models, and outputs are created. The final results are in a CSV file starting with \"final_result\" in the \"outputs/your model ID/\" folder. Open it with Excel spreadsheet software, and you can see that it has three columns as shown below. The first column is the name of the cell sample, determined by the user's input; the second column is the probability value of SoCube predicting the sample to be a doublet, ranging from 0 to 1; the third column is SoCube's prediction of the type based on the probability threshold given by the user or the default threshold of 0.5. Users can either use the probability values for subsequent custom filtering or use the third column for direct filtering. CSV file of final_result 4.2 GPU accelerated computing If you has a discrete NVIDIA graphics card and the correct CUDA configuration, you will receive the message \"Using CPU training, but GPU is available, specify '-gpu-ids ' to use GPU\". You only need to add the parameter \"-gpu-ids\" to the previous command to specify the GPU to be used. The GPU ID can be seen in the output of the nvidia-smi command mentioned earlier, 0,1,2,... which means the 1st, 2nd, 3rd... GPUs respectively (in the case of multiple GPUs) socube -i \"D:\\data\\pbmc-1C-dm.h5ad\" --gpu-ids \"0,1\" 4.3 Docker-based usage The docker-based usage is similar to the previously mentioned usage after pip installation, but requires docker to start the container, so there are some differences. \"-v\", \"--gpus\", \"--name\" are all start parameters of docker run command, \" -v\" parameter mounts the external folder to the internal path of the docker container, because socube reads the file path inside the docker container. The \"--gpus\" parameter is responsible for authorizing the number of gpu used by the container. PowerShellBashsudo docker run -v D:/data:/workspace/datasets ` –gpus all ` –name socube ` gcszhn/socube:latest ` -input \"datasets/pbmc.h5ad\" ` –gpu-ids \"0,1\" sudo docker run -v /data:/workspace/datasets \\ –gpus all \\ –name socube \\ gcszhn/socube:latest \\ -input \"datasets/pbmc.h5ad\" \\ –gpu-ids \"0,1\" \"gcszhn/socube:latest\" is the image name. The parameters before it are docker startup parameters, including folder mapping and GPU mount, and the parameters after it are SoCube parameters, which are used in the same way as before. Users can check the image name through docker images. Available image 4.4 Usage of colab Google offers a free online machine learning platform with GPU colab. Users can upload socube_colab.ipynb (available in the open source repository of this project) and scRNA-seq data to your google drive and use it for GPU-accelerated prediction. (Tip: you need to choose to enable GPU inside the notebook settings, the default is CPU). colab 4.5 Multi-process training With sufficient memory and video memory, users can use the --enable-multiprocess parameter to enable multi-process training acceleration to take full advantage of the multi-core computing of modern CPUs. socube -i your_sc.h5ad -o your_sc --gpu-ids 0 --enable-multiprocess console.log(\"plugin-popup....\");document.onclick = function(e){ e.target.tagName === \"IMG\" && window.open(e.target.src,e.target.src)}img{cursor:pointer}"},"5-problem-solution.html":{"url":"5-problem-solution.html","title":"Problem Solution","keywords":"","body":"Problem Solution 5.1 Error about lapjv lapjv is an indispensable dependency package for Socube and is an important tool for implementing the J-V algorithm. For more questions, you can go to its official repository src-d/lapjv. 1. numpy missing You need to pre-install numpy before installing certain versions of lapjv dependencies (otherwise you will see ModuleNotFoundError errors. There is no module named numpy), this is because these versions, such as v1.3.1, import numpy directly in setup.py. setup.py is the executable file of the python installer, so it will cause the installation to fail. import platform from setuptools import setup, Extension import numpy CXX_ARGS = { \"Darwin\": [\"-std=c++11\", \"-march=native\", \"-ftree-vectorize\"], \"Linux\": [\"-fopenmp\", \"-std=c++11\", \"-march=native\", \"-ftree-vectorize\"], \"Windows\": [\"/openmp\", \"/std:c++latest\", \"/arch:AVX2\"] } 2. RuntimeError: module comiled against API The following RuntimeError may exist when installing and using the binary version (wheel) of lapjv. This is because the version of the C library API used by the publisher to compile lapjv is different from the currently installed numpy. RuntimeError: module compiled against API version 0xf but this version of numpy is 0xe There are two solutions to this problem, as follows: Installing lapjv from the source so that it recompiles using the current installed numpy. Note that the C++ compiler used needs to support the version of C++ defined by CXX_ARGS in setup.py, e.g. \"-std=c++11\". The latest version of lapjv needs to use \"-std=c++17\". Therefore it is technically challenging for users without basic knowledge. Also the installation from source needs to provide a dependency on the CPP library, for windows you can install the full visual studio 2019 or download build tools directly. After the download and installation is complete, restart your computer and it will be ready to use.pip install lapjv --no-binary lapjv Install the corresponding version of numpy, but there may be conflicts with other packages that depend on the numpy version. 5.2 Error about pytables The library is a dependent library for the to_hdf API of pandas. Some versions of this package lack the required dynamic C libraries, such as tables-3.7.0-cp38-cp38-win_amd64, you can try installing other versions listed in PyPi to fix it. For other issues, you can visit its official GitHub repository. Traceback (most recent call last): File \"c:\\Users\\zhang\\anaconda3\\envs\\socube_test\\lib\\site-packages\\pandas\\compat\\_optional.py\", line 138, in import_optional_dependency module = importlib.import_module(name) File \"c:\\Users\\zhang\\anaconda3\\envs\\socube_test\\lib\\importlib\\__init__.py\", line 127, in import_module return _bootstrap._gcd_import(name[level:], package, level) File \"\", line 1014, in _gcd_import File \"\", line 991, in _find_and_load File \"\", line 975, in _find_and_load_unlocked File \"\", line 671, in _load_unlocked File \"\", line 843, in exec_module File \"\", line 219, in _call_with_frames_removed File \"c:\\Users\\zhang\\anaconda3\\envs\\socube_test\\lib\\site-packages\\tables\\__init__.py\", line 45, in from .utilsextension import get_hdf5_version as _get_hdf5_version ImportError: DLL load failed while importing utilsextension: 找不到指定的模块。 During handling of the above exception, another exception occurred: Traceback (most recent call last): File \"c:\\Users\\zhang\\anaconda3\\envs\\socube_test\\lib\\concurrent\\futures\\process.py\", line 239, in _process_worker r = call_item.fn(*call_item.args, **call_item.kwargs) File \"d:\\life_matters\\IDRB\\深度组学\\单细胞组学\\SoCube\\src\\socube\\utils\\concurrence.py\", line 74, in wrapper return func(*args, **kwargs) File \"d:\\life_matters\\IDRB\\深度组学\\单细胞组学\\SoCube\\src\\socube\\utils\\io.py\", line 262, in writeHdf data.to_hdf(file, key=key, mode=mode, **kwargs) File \"c:\\Users\\zhang\\anaconda3\\envs\\socube_test\\lib\\site-packages\\pandas\\core\\generic.py\", line 2763, in to_hdf pytables.to_hdf( File \"c:\\Users\\zhang\\anaconda3\\envs\\socube_test\\lib\\site-packages\\pandas\\io\\pytables.py\", line 311, in to_hdf with HDFStore( File \"c:\\Users\\zhang\\anaconda3\\envs\\socube_test\\lib\\site-packages\\pandas\\io\\pytables.py\", line 572, in __init__ tables = import_optional_dependency(\"tables\") File \"c:\\Users\\zhang\\anaconda3\\envs\\socube_test\\lib\\site-packages\\pandas\\compat\\_optional.py\", line 141, in import_optional_dependency raise ImportError(msg) ImportError: Missing optional dependency 'pytables'. Use pip or conda to install pytables. 5.3 Error about docker 1. nvidia-container-cli: initialization error Docker relies on the WSL2 backend by default under Windows. The earlier version of WSL2 in Windows 10 does not support GPU, so you will receive the following error. Running hook #0:: error running hook: exit status 1, stdout: , stderr: nvidia-container-cli: initialization error: driver error: failed to process request: unknown Users can choose to upgrade to a newer version such as Windows 10 21H2. It is recommended to use docker on a linux server with a GPU, or you can choose to run it purely on CPU, but it will be slower. docker run ` -v :/workspace/datasets ` gcszhn/socube:latest ` -i datasets/ console.log(\"plugin-popup....\");document.onclick = function(e){ e.target.tagName === \"IMG\" && window.open(e.target.src,e.target.src)}img{cursor:pointer}"},"6-parameters.html":{"url":"6-parameters.html","title":"Parameters","keywords":"","body":"Parameters SoCube's parameters help can be obtained by executing socube --help in the terminal, which is explained here. socube's help file output will automatically select Chinese or English depending on the user's system language and locale. If necessary, the user can change the system language setting to switch, for example, setting the LC_ALL environment variable to en_US under linux. SoCube help --help The abbreviation is \"-h\". Get above parameter usage help. --version The abbreviation is \"-v\". Print SoCube's version and copyright. --input The abbreviation is \"-i\". As mentioned before, this parameter is used to specify the data input file, which can receive two data formats, and it will not be repeated here. --output The abbreviation is \"-o\". This parameter is used to customize the output path of the result, which will be created automatically if the path does not exist. As mentioned before, by default, the result output will be in the same directory as the input file, and the user can use this parameter to customize it. Example: --output D:/data/. --gpu-ids As mentioned before, this parameter is used to specify the serial number of the GPU devices involved in the compute acceleration. It can be a single serial number or multiple serial numbers separated by commas, note that the comma is an English comma with no spaces, the default is not set, use CPU. Example: --gpu-ids 0,1,2. --seed This parameter is used to specify the random number seed for the random process in the software calculation, the default is not set. Example: --seed 4067. --k This parameter is used to specify the k value for model k-fold cross-training, the default is 5. Example: --k 4. --adj-factor This parameter is the adjustment factor for the doublet expression level. By default, the expression level of the doublet is assumed to be twice that of the singlet, but there are fluctuations in the actual situation and the expression level can be changed by adjusting this factor. The default is 1.0. Example: --adj-factor 0.8. --dim This parameter is used to specify the number of channels for constructing features, and also the target dimension for gene feature reduction, the default is 10. Example: --dim 5. --cube-id This parameter is used to reuse the previously generated features. All features will be saved in the \"embedding\" subdirectory. This parameter is the ID of the specific feature in that subdirectory, which is a \"XXXXXXX-XXXXXX-XXX\" style string. Example: --cube-id 20220704-120122-854. --only-embedding The user may simply want to use the SoCube feature embedding strategy but does not need to detect and remove the doublets, using this parameter means embedding only. --learning-rate The abbreviation is \"-lr\". This parameter is the training learning rate of an artificial intelligence deep neural network. This parameter can have a significant impact on the detection results. The default value is 1e-3, and can be customized if necessary. Example: --learning-rate 1e-4. --epochs The abbreviation is \"-e\". This parameter refers to the maximum number of rounds of neural network training. However, in general, training will be completed before the default maximum number of rounds of 100 is reached. Example: --epochs 50. --train-batch-size This parameter is used to specify the batch dataset size for neural network training, the default is 64. larger batch data set size tends to have better training effect, but occupies more CPU memory or GPU video memory. Users can adjust it according to the actual situation of their devices. Example: --train-batch-size 32. --valid-batch-size Similar to the previous, this parameter is used to specify the batch dataset size for neural network validation and defaults to 512. Since the validation process consumes significantly less memory than the training process, the default value is larger. Example: --valid-batch-size 256. --infer-batch-size Similar to the previous, this parameter is used to specify the batch dataset size for neural network prediction, default is 400. example: --infer-batch-size 256. --threshold The abbreviation is \"-t\". This parameter is used to specify the probability threshold for classifying doublets and singlets, the default is 0.5. As explained in the previous CSV results file, cell samples larger than the threshold are determined to be doublets. Example: -t 0.5. --enable-validation The abbreviation is \"-ev\". This parameter is a position parameter with no subsequent values. Use it to enable result validation, which is used only to reproduce the evaluation metrics of the results. It requires that the data input format is H5AD and that the \"obs\" property of the AnnData object has a \"type\" column with the content \"doublet \" or \"singlet\", which indicates the real label of the dataset. --enable-multiprocess The abbreviation is \"-mp\". This parameter is a position parameter with no subsequent values. Use it to enable multi-process training. In this case, SoCube creates k sub-processes to train k sub-models in parallel (the k value is specified by the --k parameter). Multi-process training can improve the detection speed, but it is a space-for-time operation, which increases memory and video memory overhead, so users need to decide whether to enable multi-process according to their dataset size and memory size. Of course, users can adjust the previous batch parameter to reduce memory usage. --mail This parameter specifies the email address to be used for result notification, which can be used by any mail provider that supports SMTP protocol, such as QQmail, Gmail, etc. It needs to be used in conjunction with several subsequent mailbox parameters. --mail-server This parameter specifies the SMTP server domain name of the mail provider. Please consult the email provider you are using for details. Example: --mail-server smtp.gmail.com. --mail-port This parameter specifies the SMTP service port of the mail provider. Please consult the email provider you are using for details. Example: --mail-port 994. --mail-passwd This parameter specifies the password of the email. Generally it is the login password of web email, unless otherwise agreed by the email provider, please consult the email provider you are using for details. --enable-ssl Enabling this parameter means that the mail service uses SSL encryption. console.log(\"plugin-popup....\");document.onclick = function(e){ e.target.tagName === \"IMG\" && window.open(e.target.src,e.target.src)}img{cursor:pointer}"},"term.html":{"url":"term.html","title":"Terminology","keywords":"","body":"Terminology Terminology Explanation CPU Computer terminology. Central process unit, which is often referred to as the core part of the computer chip. It is responsible for the scheduling and operation of the entire computer. GPU Computer terminology. Graphics process unit, which is often referred to as the core part of a graphics card. It is responsible for the conversion of digital signals to image analog signals, while modern GPUs can be used for computational acceleration of deep learning models for artificial intelligence. RAM Computer terminology. Random access memory, which is often referred to as a kind of memory. It can be accessed efficiently, but cannot save data after a power failure. pip Computer terminology. A build-in package manager for the Python, used to install SoCube V1.0. docker Computer terminology. A technology that isolates application software and its dependent software environment from the physical machine. SMTP Computer terminology. Simple mail transfer protocol, a mail service by which mail providers allow operations from third-party mail clients by supporting the protocol. scRNA-seq Bioinformatics terminology. Single-cell RNA sequencing. which is used to detect the expression of genes in a single cell. CNN Artificial intelligence terminology. Convolutional neural network, one of the most common types of artificial intelligence models for image-like data. SoCube uses CNNs to build its models. WSL Computer terminology. Windows subsystem linux, the linux subsystem developed by Microsoft, similar to the virtual machines provided by third parties such as VMare. console.log(\"plugin-popup....\");document.onclick = function(e){ e.target.tagName === \"IMG\" && window.open(e.target.src,e.target.src)}img{cursor:pointer}"},"reference.html":{"url":"reference.html","title":"Reference","keywords":"","body":"Reference Klein AM, Mazutis L, Akartuna I et al. Droplet barcoding for single-cell transcriptomics applied to embryonic stem cells, Cell 2015;161:1187-1201. Cao J, Packer JS, Ramani V et al. Comprehensive single-cell transcriptional profiling of a multicellular organism, Science 2017;357:661-667. Gierahn TM, Wadsworth MH, 2nd, Hughes TK et al. Seq-Well: portable, low-cost RNA sequencing of single cells at high throughput, Nat Methods 2017;14:395-398. Macosko EZ, Basu A, Satija R et al. Highly Parallel Genome-wide Expression Profiling of Individual Cells Using Nanoliter Droplets, Cell 2015;161:1202-1214. Zheng GX, Terry JM, Belgrader P et al. Massively parallel digital transcriptional profiling of single cells, Nat Commun 2017;8:14049. Rosenberg AB, Roco CM, Muscat RA et al. Single-cell profiling of the developing mouse brain and spinal cord with split-pool barcoding, Science 2018;360:176-182. Xi NM, Li JJ. Benchmarking Computational Doublet-Detection Methods for Single-Cell RNA Sequencing Data, Cell Syst 2021;12:176-194 e176. console.log(\"plugin-popup....\");document.onclick = function(e){ e.target.tagName === \"IMG\" && window.open(e.target.src,e.target.src)}img{cursor:pointer}"}}