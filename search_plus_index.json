{"./":{"url":"./","title":"Introduction","keywords":"","body":"Introduction SoCube workflow 1.1 Basic Information SoCube V1.0 is terminal command-based software written in Python without a visual user interface (GUI), and can run on any computing server, personal computer, etc. that can run the Python language. 1.2 Writing Purpose The User Manual of ZJU Single Cell High Throughput Sequencing Dimer Assay Software (V1.0) (hereinafter referred to as \"the Manual\") is a user's guide for ZJU Single Cell High Throughput Sequencing Dimer Assay Software (V1.0). 1.3 Background High-throughput single-cell RNA sequencing (scRNA-seq) is widely used in biomedical research [1-6]. However, due to the limitations of sequencing technology, a dimer (or multimer) formed by the combination of two (or more) cells will be generated during the sequencing process. Dimers are equivalent to a cell type that is not otherwise present in the sample and can severely interfere with the true statistical distribution of cells and genes, hereby affecting downstream studies with distribution dependence [7]. Therefore, the Laboratory of Innovative Drug Research and Bioinformatics at Zhejiang University (hereinafter referred to as \"we\") developed SoCube to detect dimers generating in single-cell high-throughput sequencing. console.log(\"plugin-popup....\");document.onclick = function(e){ e.target.tagName === \"IMG\" && window.open(e.target.src,e.target.src)}img{cursor:pointer}"},"2-requirement.html":{"url":"2-requirement.html","title":"Requirement","keywords":"","body":"Requirement 2.1 Hardware SoCube's hardware development environment is based on the XII Gen Intel I7-12700F CPU and the NVIDIA GeForce RTX 3060 GPU. SoCube is theoretically capable of running on any device that can run Python and PyTorch. The recommended hardware runtime environment is as follows: RAM capacity of not less than 8GB CPU core number not less than 6 cores NVIDIA discrete graphics card with CUDA acceleration and no less than 4GB of video memory 2.2 Software SoCube is written in Python v3.8, and Visual Studio Code v1.68.1 is used as the code writing tool. The development OS is Windows 11. SoCube supports use in any software environment that can run Python and PyTorch. The recommended software runtime environment is as follows: OS: Windows 10/11, Linux CentOS 7/8, Mac OS Python: v3.7 and above PyTorch: v1.8.1 and higher GPU versions console.log(\"plugin-popup....\");document.onclick = function(e){ e.target.tagName === \"IMG\" && window.open(e.target.src,e.target.src)}img{cursor:pointer}"},"3-install.html":{"url":"3-install.html","title":"Installation","keywords":"","body":"Installation 3.1 CUDA Installation SoCube is developed based on deep convolutional neural networks, and we strongly recommend users to use GPU accelerated computation in an environment with NVIDIA GPU and NVIDIA CUDA compute suite. For having a CUDA-enabled NVIDIA GPU, users first need to install CUDA, which can be downloaded and installed from the NVIDIA. Nvidia cuda download page After the installation is complete, users can enter \"nvidia-smi\" in the terminal to view their graphics card information and CUDA version information, as shown below, the graphics card is GeForce RTX 3060, the driver version is 516.59, CUDA version is 11.7 nvia-smi nvidia-smi 3.2 SoCube Installation PipDockerpip install socube # pip installation socube -v # check the installed version SoCube has been packaged and released to the official Python repository PyPi. Users can open a terminal (such as Windows PowerShell, Bash, etc.) and use the pip command to install it. For users in China, it is recommended to use the Tsinghua University image source to accelerate the download during installation. The following uses the Windows operating system as an example.1. Python InstallationSoCube is a software developed based on Python, and it needs to rely on Python interpreter to run the software. Users need to download Python from official Python website.official Python websiteAs shown below, follow the installation package prompts to install Python and check the box to add Python to the PATH environment variable (this environment variable defines the search path for terminal commands; if you do not add it, you cannot use Python directly in the terminal).Python installation page2. Access to terminal command environmentPip is a package manager provided by Python to download all kinds of packages developed by Python, but it needs to be used in a terminal. Two kinds of terminals are provided under Windows, Windows PowerShell and Cmd, we recommend using PowerShell. use \"Win+R \" shortcut and run powershell to quickly enter PowerShell terminal.Run powershell3. Execute the pip command to installExecute the aforementioned command in the terminal to install SoCube V1.0, which is recommended for users in China to use the Tsinghua University image source acceleration software to download. When you see \"Successfully installed *** socube-1.0\" , it means the download and installation are successful. After successful installation, continue to enter socube -v in the current terminal to see the software version prompt. The -i parameter is recommended for users in China (https://pypi.tuna.tsinghua.edu.cn/simple/).pip install socube==1.0 -f https://pypi.tuna.tsinghua.edu.cn/simple/ 4. Notes on PyTorchAlthough PyTorchid is automatically installed when executing pip install socube, some image versions may download the CPU version, so users are advised to check if the installed version supports GPU (torch.cuda.is_available() will be True when GPU and CUDA are properly configured). It is recommended to download torch from the official PyTorch website or from a specific official PyTorch pip source.pip install torch==1.8.1+cu111 torchvision==0.9.1+cu111 -f https://download.pytorch.org/whl/torch_stable.html sudo docker pull gcszhn/socube:latest Docker is a containerized technology that isolates software in a sandbox, called a container. The containers are isolated from the physical device (called the container's host) and from the containers to each other. The container has the complete software environment in which the application runs and does not depend on the host software environment at all. Containers can be published as images and shared between devices with docker installed without additional installation. docker image have been built by SoCube and published on Docker Hub. Users who already have docker installed can obtain SoCube by executing the above command in the terminal. In addition, interested users can package a custom docker image of their own, which Dockerflie has made available open source.git clone https://github.com/GCS-ZHN/socube.git cd socube sudo docker build docker -t gcszhn/socube console.log(\"plugin-popup....\");document.onclick = function(e){ e.target.tagName === \"IMG\" && window.open(e.target.src,e.target.src)}img{cursor:pointer}"},"4-usage.html":{"url":"4-usage.html","title":"Usage","keywords":"","body":"Usage 4.1 Basic use 1. Format of input data SoCube's data input is a scRNA-seq UMI count matrix with rows of cells, columns of genes, and values of UMI counts. SoCube accepts two data formats: (1)DataFrame objects in HDF5 format saved in Python pandas library; (2)AnnData objects in H5AD format (a customized HDF5 format) saved in Python anndata library. People working in the field of single-cell omics have some basic knowledge of data processing, so this manual does not specifically describe how to convert from other formats to the above formats. 2. Running SoCube SoCube runs under the terminal like the aforementioned pip. The advantage is that it can run on many servers without GUI pages and is not limited by the GUI. Assuming that the input file is \"D:\\data\\pbmc-1C-dm.h5ad\", you can enter the following command in the terminal to run the software, and then you will see the software start and output logs in the terminal. The parameter -i (or --input) indicates the specified input file. socube --input \"D:\\data\\pbmc-1C-dm.h5ad\" Start-up socube When the software is finished, the doublet detection results and the intermediate files will be put together with the input files by default, resulting in the embedding, plots, models, and outputs folders. The final results are in a CSV file starting with \"final_result\" in the \"outputs/your model ID/\" folder. Open it with Excel spreadsheet software, and you can see that it has three columns as shown below. The first column is the name of the cell sample entered, determined by the user's input; the second column is the probability value of SoCube predicting the sample to be a doublet, ranging from 0\\ to 1; the third column is SoCube's prediction of the type based on the probability threshold given by the user or the default threshold of 0.5, with singlet being a single normal cell and doublet being a doublet.Users can either use the probability values for subsequent custom filtering or use the third column for direct filtering. CSV file of final\\_result 4.2 GPU accelerated computing If you has a discrete NVIDIA graphics card and the correct CUDA configuration, you will receive the message \"Using CPU training, but GPU is available, specify '-gpu-ids ' to use GPU\". You only need to add the parameter \"-gpu-ids\" to the previous command to specify the GPU to be used. The GPU ID can be seen in the output of the nvidia-smi command mentioned earlier, 0,1,2,... which means the 1st, 2nd, 3rd... GPUs respectively (in the case of multiple GPUs) socube -i \"D:\\data\\pbmc-1C-dm.h5ad\" --gpu-ids \"0,1\" 4.3 Docker-based use The docker-based use is essentially the same as the previously mentioned use after pip installation, but requires docker to start the container, so there are some differences. Where \"-v\", \"--gpus\", \"--name\" are all start parameters of docker run command, \" -v\" parameter mounts the external folder to the internal path of the docker container. Remember not to forget, because socube reads the file path inside the docker container. The \"--gpus\" parameter is responsible for authorizing the number of gpu used by the container. PowerShellBashsudo docker run -v D:/data:/workspace/datasets ` –gpus all ` –name socube ` gcszhn/socube:latest ` -input \"datasets/pbmc.h5ad\" ` –gpu-ids \"0,1\" sudo docker run -v /data:/workspace/datasets \\ –gpus all \\ –name socube \\ gcszhn/socube:latest \\ -input \"datasets/pbmc.h5ad\" \\ –gpu-ids \"0,1\" The image name is “gcszhn/socube:latest”, the former one is the docker startup parameters, including folder mapping and GPU mounting, and the latter one is the SoCube parameters, which are used in the same way as before. Users can check the image name through docker images. Available image 4.4 Use of colab Google offers a free online machine learning platform with GPU colab. Users can upload socube_colab.ipynb (available in the open source repository of this project) and scRNA-seq data to your google drive and use it for GPU-accelerated prediction. (Tip: you need to choose to enable GPU inside the notebook settings, the default is for CPU). colab 4.5 Multi-process training With sufficient video memory, users can use the --enable-multiprocess parameter to enable multiprocess training acceleration. socube -i your_sc.h5ad -o your_sc --gpu-ids 0 --enable-multiprocess console.log(\"plugin-popup....\");document.onclick = function(e){ e.target.tagName === \"IMG\" && window.open(e.target.src,e.target.src)}img{cursor:pointer}"},"5-problem-solution.html":{"url":"5-problem-solution.html","title":"Problem Solution","keywords":"","body":"Problem Solution 5.1 Error in lapjv lapjv is an indispensable dependency package for Socube and is an important tool for implementing the J-V algorithm. For more questions, you can go to its official repository src-d/lapjv. 1. numpy missing You need to pre-install numpy before installing certain versions of lapjv dependencies (otherwise you will see ModuleNotFoundError errors. There is no module named numpy), this is because these versions, such as v1.3.1, import numpy directly in setup.py. import platform from setuptools import setup, Extension import numpy CXX_ARGS = { \"Darwin\": [\"-std=c++11\", \"-march=native\", \"-ftree-vectorize\"], \"Linux\": [\"-fopenmp\", \"-std=c++11\", \"-march=native\", \"-ftree-vectorize\"], \"Windows\": [\"/openmp\", \"/std:c++latest\", \"/arch:AVX2\"] } 2. RuntimeError: module comiled against API The following RuntimeError may exist when installing and using the binary version (wheel) of lapjv. This is because the version of the C library API used by the publisher to compile lapjv is different from the currently installed numpy. RuntimeError: module compiled against API version 0xf but this version of numpy is 0xe There are two solutions to this problem, as follows: Installing lapjv from the source so that it recompiles using the now installed numpy. Note that the C++ compiler used needs to support the version of C++ defined by CXX_ARGS in setup.py, e.g. \"-std=c++11\". The latest version of lapjv needs to use \"-std=c++17\". Therefore it is technically challenging for users without basic knowledge. Also the installation from source needs to provide a dependency on the CPP library, for windows you can install the full visual studio 2019 or download build tools directly.After the download and installation is complete, restart your computer and you are ready to use.pip install lapjv --no-binary lapjv Install the corresponding version of numpy, although there may be conflicts with other packages that depend on the numpy version. 5.2 Error in PyTables The library is a dependent library for the TO_HDF API of pandas.Some versions of this package lack the required dynamic C libraries, such as tables-3.7.0-cp38-cp38-win_amd64, you can try installing other versions listed in PyPi to fix it. For other issues, you can check out its official GitHub repository. Traceback (most recent call last): File \"c:\\Users\\zhang\\anaconda3\\envs\\socube_test\\lib\\site-packages\\pandas\\compat\\_optional.py\", line 138, in import_optional_dependency module = importlib.import_module(name) File \"c:\\Users\\zhang\\anaconda3\\envs\\socube_test\\lib\\importlib\\__init__.py\", line 127, in import_module return _bootstrap._gcd_import(name[level:], package, level) File \"\", line 1014, in _gcd_import File \"\", line 991, in _find_and_load File \"\", line 975, in _find_and_load_unlocked File \"\", line 671, in _load_unlocked File \"\", line 843, in exec_module File \"\", line 219, in _call_with_frames_removed File \"c:\\Users\\zhang\\anaconda3\\envs\\socube_test\\lib\\site-packages\\tables\\__init__.py\", line 45, in from .utilsextension import get_hdf5_version as _get_hdf5_version ImportError: DLL load failed while importing utilsextension: 找不到指定的模块。 During handling of the above exception, another exception occurred: Traceback (most recent call last): File \"c:\\Users\\zhang\\anaconda3\\envs\\socube_test\\lib\\concurrent\\futures\\process.py\", line 239, in _process_worker r = call_item.fn(*call_item.args, **call_item.kwargs) File \"d:\\life_matters\\IDRB\\深度组学\\单细胞组学\\SoCube\\src\\socube\\utils\\concurrence.py\", line 74, in wrapper return func(*args, **kwargs) File \"d:\\life_matters\\IDRB\\深度组学\\单细胞组学\\SoCube\\src\\socube\\utils\\io.py\", line 262, in writeHdf data.to_hdf(file, key=key, mode=mode, **kwargs) File \"c:\\Users\\zhang\\anaconda3\\envs\\socube_test\\lib\\site-packages\\pandas\\core\\generic.py\", line 2763, in to_hdf pytables.to_hdf( File \"c:\\Users\\zhang\\anaconda3\\envs\\socube_test\\lib\\site-packages\\pandas\\io\\pytables.py\", line 311, in to_hdf with HDFStore( File \"c:\\Users\\zhang\\anaconda3\\envs\\socube_test\\lib\\site-packages\\pandas\\io\\pytables.py\", line 572, in __init__ tables = import_optional_dependency(\"tables\") File \"c:\\Users\\zhang\\anaconda3\\envs\\socube_test\\lib\\site-packages\\pandas\\compat\\_optional.py\", line 141, in import_optional_dependency raise ImportError(msg) ImportError: Missing optional dependency 'pytables'. Use pip or conda to install pytables. 5.3 Error using docker image 1. nvidia-container-cli: initialization error Docker relies on the WSL2 backend by default under Windows.The earlier version of WSL2 in Windows 10 does not support GPU, so you will receive the following error. Running hook #0:: error running hook: exit status 1, stdout: , stderr: nvidia-container-cli: initialization error: driver error: failed to process request: unknown Users can choose to upgrade to a newer version such as Windows 10 21H2. It is recommended to use docker on a linux server with a GPU, or you can choose to run it purely on CPU, but it will be slower. docker run ` -v :/workspace/datasets ` gcszhn/socube:latest ` -i datasets/ console.log(\"plugin-popup....\");document.onclick = function(e){ e.target.tagName === \"IMG\" && window.open(e.target.src,e.target.src)}img{cursor:pointer}"},"6-parameters.html":{"url":"6-parameters.html","title":"Parameters","keywords":"","body":"Parameters SoCube's parameters help can be obtained by executing socube --help in the terminal, which is explained here. socube's help file output will automatically select Chinese or English depending on the user's system language and locale. If necessary, the user can change the system language setting to switch, for example, setting the LC_ALL environment variable to en_US under linux. --input The abbreviation is \"-i\". As mentioned before, this parameter is used to specify the data input file, which can receive two data formats, and will not be repeated here. --output The abbreviation is \"-o\". This parameter is used to customize the output path of the result, which will be created automatically if the path does not exist. As mentioned before, by default, the result output will be in the same directory as the input file, and the user can use this parameter to customize it. Example: --output D:/data/ --gpu-ids As mentioned before, this parameter is used to specify the serial number of the GPU devices involved in the compute acceleration. It can be a single serial number or multiple serial numbers separated by commas, note that the comma is an English comma with no spaces, the default is not set, use CPU. Example: --gpu-ids 0,1,2. --seed This parameter is used to specify the random number seed for the random process in the software calculation, the default is not set. Example: --seed 4067. --k This parameter is used to specify the k value for model k-fold cross-training, the default is 5. Example: -- k 4. --adj-factor This parameter is the adjustment factor for the doublet expression level. By default, the expression level of the doublet is assumed to be twice that of the monomer, but the actual situation fluctuates and the expression level can be changed by adjusting this factor. The default is 1.0. Example: --adj-factor 0.8. --dim This parameter is used to specify the number of channels for constructing features, and also the target dimension for gene feature downscaling, the default is 10. Example: --dim 5. --cube-id This parameter is used to reuse the previously generated features. All features will be saved in the embedding subdirectory. This parameter is the ID of the specific feature in that subdirectory, which is a \"XXXXXXX-XXXXXX-XXX\" style string. Example: --cube-id 20220704-120122-854. --learning-rate The abbreviation is \"-lr\". This parameter is the training learning rate of an artificial intelligence deep neural network. This parameter can have a significant impact on the detection results. The default value is 1e-3, and can be customized if the user feels the need to do so. Example: --learning-rate 1e-4. --epochs The abbreviation is \"-e\". This parameter refers to the maximum number of rounds of neural network training. However, in general, training will be completed before the default maximum number of rounds of 100 is reached. Example: --epochs 50. --train-batch-size This parameter is used to specify the batch data set size for neural network training, the default is 64. larger batch data set size tends to have better training effect, but occupies more CPU memory or GPU video memory. Users can adjust it according to the actual situation of their devices. Example: --train-batch-size 32. --valid-batch-size Similar to the previous, this parameter is used to specify the batch dataset size for neural network validation and defaults to 512. Since the validation process consumes significantly less memory than the training process, the default value is larger. Example: --valid-batch-size 256. --infer-batch-size Similar to the previous, this parameter is used to specify the batch dataset size for neural network prediction, default is 400. example: --infer-batch-size 256. --threshold The abbreviation is \"-t\". This parameter is used to specify the probability threshold for classifying doublets and singlets, the default is 0.5. As explained in the previous CSV results file, cell samples larger than the threshold are determined to be doublets. Example: -t 0.5. --enable-validation The abbreviation is \"-ev\". This parameter is a position parameter with no subsequent values. Use it to enable result validation, which is used only to reproduce the evaluation metrics of the results. It requires that the data input format is H5AD and that the \"obs\" property of the AnnData object has a \"type\" column with the content \"doublet \" or \"singlet\", which indicates the real label of the dataset. --enable-multiprocess The abbreviation is \"-mp\". This parameter is a position parameter with no subsequent values. Use it to enable multi-process training. In this case, SoCube creates k sub-processes to train k sub-models in parallel (the k value is specified by the -k parameter). Multi-process training can improve the detection speed, but it is a space-for-time operation, which increases memory and video memory overhead, so users need to decide whether to enable multi-process according to their dataset size and memory size. Of course, users can adjust the previous batch parameter to reduce memory usage. --mail This parameter specifies the email address to be used for result notification, which can be used by any mail provider that supports SMTP protocol, such as QQmail, Gmail, etc. It needs to be used in conjunction with several subsequent mailbox parameters. --mail-server This parameter specifies the SMTP server domain name of the mail provider. Please consult the email provider you are using for details. Example: --mail-server smtp.gmail.com. --mail-port This parameter specifies the SMTP service port of the mail provider. Please consult the email provider you are using for details. Example: --mail-port 994. --mail-passwd This parameter specifies the password of the email. Generally it is the login password of web email, unless otherwise agreed by the email provider, please consult the email provider you are using for details. --enable-ssl Enabling this parameter means that the mail service uses SSL encryption. console.log(\"plugin-popup....\");document.onclick = function(e){ e.target.tagName === \"IMG\" && window.open(e.target.src,e.target.src)}img{cursor:pointer}"},"term.html":{"url":"term.html","title":"Terminology","keywords":"","body":"Terminology Terminology Explanation CPU Computer terminology. Central process unit, which is often referred to as the core part of the computer chip. It is responsible for the scheduling and operation of the entire computer. GPU Computer terminology. Graphics process unit, which is often referred to as the core part of a graphics card. It is responsible for the conversion of digital signals to image analog signals, while modern GPUs can be used for computational acceleration of deep learning models for artificial intelligence. RAM Computer terminology. Random access memory, which is often referred to as a kind of memory. It can be accessed efficiently, but cannot save data after a power failure. pip Computer terminology. A build-in package manager for the Python, used to install SoCube V1.0. docker Computer terminology. A technology that isolates application software and its dependent software environment from the physical machine. SMTP Computer terminology. Simple mail transfer protocol, a mail service by which mail providers allow operations from third-party mail clients by supporting the protocol. scRNA-seq Bioinformatics terminology. Single-cell RNA sequencing. which is used to detect the expression of genes in a single cell. CNN Artificial intelligence terminology. Convolutional neural network, one of the most common types of artificial intelligence models for image-like data. SoCube uses CNNs to build its models. WSL Computer terminology. Windows subsystem linux, the linux subsystem developed by Microsoft, similar to the virtual machines provided by third parties such as VMare. console.log(\"plugin-popup....\");document.onclick = function(e){ e.target.tagName === \"IMG\" && window.open(e.target.src,e.target.src)}img{cursor:pointer}"},"reference.html":{"url":"reference.html","title":"Reference","keywords":"","body":"Reference Klein AM, Mazutis L, Akartuna I et al. Droplet barcoding for single-cell transcriptomics applied to embryonic stem cells, Cell 2015;161:1187-1201. Cao J, Packer JS, Ramani V et al. Comprehensive single-cell transcriptional profiling of a multicellular organism, Science 2017;357:661-667. Gierahn TM, Wadsworth MH, 2nd, Hughes TK et al. Seq-Well: portable, low-cost RNA sequencing of single cells at high throughput, Nat Methods 2017;14:395-398. Macosko EZ, Basu A, Satija R et al. Highly Parallel Genome-wide Expression Profiling of Individual Cells Using Nanoliter Droplets, Cell 2015;161:1202-1214. Zheng GX, Terry JM, Belgrader P et al. Massively parallel digital transcriptional profiling of single cells, Nat Commun 2017;8:14049. Rosenberg AB, Roco CM, Muscat RA et al. Single-cell profiling of the developing mouse brain and spinal cord with split-pool barcoding, Science 2018;360:176-182. Xi NM, Li JJ. Benchmarking Computational Doublet-Detection Methods for Single-Cell RNA Sequencing Data, Cell Syst 2021;12:176-194 e176. console.log(\"plugin-popup....\");document.onclick = function(e){ e.target.tagName === \"IMG\" && window.open(e.target.src,e.target.src)}img{cursor:pointer}"}}